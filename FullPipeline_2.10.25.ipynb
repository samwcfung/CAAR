{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba810c10-2644-4187-9907-e5f80c8f8599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Starting processing of pair at 2025-02-10 15:43:50.847064:\n",
      "INFO:__main__:TIF: Disinhib1_7.23.20_ipsi2_0um_cor.tif\n",
      "INFO:__main__:ROI: RoiSet_m1_s3_0um.zip\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27156\\1924005325.py:137: RuntimeWarning: overflow encountered in exp\n",
      "  return (a * np.exp(-b * x)) + (c * np.exp(-d * x))\n",
      "INFO:__main__:Corrected image saved as a memmap at F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected.dat\n",
      "INFO:__main__:Time for Bleach Correction: 195.24 seconds\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_001.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_002.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_003.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_004.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_005.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_006.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_007.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_008.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_009.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_010.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_011.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_012.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_013.png\n",
      "INFO:__main__:Saved mask: F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_masks\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_014.png\n",
      "INFO:__main__:Time for ROI Conversion: 1.31 seconds\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_001.png: Distance to lamina = 387.09 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_002.png: Distance to lamina = 396.62 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_003.png: Distance to lamina = 369.45 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_004.png: Distance to lamina = 504.09 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_005.png: Distance to lamina = 472.03 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_006.png: Distance to lamina = 528.10 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_007.png: Distance to lamina = 774.15 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_008.png: Distance to lamina = 278.11 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_009.png: Distance to lamina = 633.94 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_010.png: Distance to lamina = 853.52 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_011.png: Distance to lamina = 276.52 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_012.png: Distance to lamina = 409.24 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_013.png: Distance to lamina = 431.90 pixels\n",
      "DEBUG:__main__:ROI Disinhib1_7.23.20_ipsi2_0um_cor_corrected_mask_014.png: Distance to lamina = 470.90 pixels\n",
      "INFO:__main__:Time for Video Loading: 0.42 seconds\n",
      "INFO:__main__:Time for Fluorescence Extraction: 0.39 seconds\n",
      "INFO:__main__:Time for dF/F Calculation: 0.13 seconds\n",
      "INFO:__main__:Saved dF/F traces to F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_dff_traces.pkl\n",
      "INFO:__main__:Time for Metrics Computation: 0.36 seconds\n",
      "INFO:__main__:Saved fluorescence metrics, background info, and distances to F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_fluorescence_metrics.xlsx\n",
      "INFO:__main__:Saved background traces to F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\Disinhib1_7.23.20_ipsi2_0um_cor_corrected_background_traces.pkl\n",
      "INFO:__main__:Time for Fluorescence Analysis: 3.01 seconds\n",
      "INFO:__main__:Time for Total time for Disinhib1_7.23.20_ipsi2_0um_cor.tif: 199.57 seconds\n",
      "INFO:__main__:Successfully processed pair in 199.57 seconds\n",
      "INFO:__main__:\n",
      "Starting processing of pair at 2025-02-10 15:47:10.420892:\n",
      "INFO:__main__:TIF: Disinhib1_7.23.20_ipsi2_10um_cor.tif\n",
      "INFO:__main__:ROI: RoiSet_m1_s3_10um.zip\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27156\\1924005325.py:137: RuntimeWarning: overflow encountered in exp\n",
      "  return (a * np.exp(-b * x)) + (c * np.exp(-d * x))\n",
      "ERROR:__main__:Error processing Disinhib1_7.23.20_ipsi2_10um_cor.tif: [Errno 22] Invalid argument: 'F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\\\Disinhib1_7.23.20_ipsi2_10um_cor_corrected.dat'\n",
      "INFO:__main__:\n",
      "Starting processing of pair at 2025-02-10 15:47:37.039245:\n",
      "INFO:__main__:TIF: Disinhib1_7.23.20_ipsi2_25um_cor.tif\n",
      "INFO:__main__:ROI: RoiSet_m1_s3_25um.zip\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27156\\1924005325.py:137: RuntimeWarning: overflow encountered in multiply\n",
      "  return (a * np.exp(-b * x)) + (c * np.exp(-d * x))\n",
      "ERROR:__main__:Error processing Disinhib1_7.23.20_ipsi2_25um_cor.tif: [Errno 22] Invalid argument: 'F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\\\\Disinhib1_7.23.20_ipsi2_25um_cor_corrected.dat'\n",
      "INFO:__main__:\n",
      "Total processing time for all pairs: 253.85 seconds\n"
     ]
    }
   ],
   "source": [
    "#V1.2.10.25\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from scipy.optimize import curve_fit\n",
    "import logging\n",
    "from typing import Tuple, Dict, Optional\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage.draw import polygon\n",
    "from roifile import roiread\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "class CalciumImagingAnalysis:\n",
    "    def __init__(self, base_dir: str, video_dims: Tuple[int, int] = (1080, 1920)):\n",
    "        self.base_dir = base_dir\n",
    "        self.video_dims = video_dims\n",
    "        self.memmap_path = None\n",
    "        self.current_base_name = None\n",
    "        self._video_cache = None\n",
    "        self.processing_times = {}  # Add timing dictionary\n",
    "        self.background_values = {}  # Add background values dictionary\n",
    "\n",
    "    def log_time(self, stage: str, start_time: float):\n",
    "        \"\"\"Log the elapsed time for a processing stage\"\"\"\n",
    "        elapsed = time.time() - start_time\n",
    "        self.processing_times[stage] = elapsed\n",
    "        logger.info(f\"Time for {stage}: {elapsed:.2f} seconds\")\n",
    "        return elapsed\n",
    "    \n",
    "    def find_matching_files(self) -> list:\n",
    "        \"\"\"\n",
    "        Find matching .tif and .zip files based on concentration patterns.\n",
    "        \n",
    "        Returns:\n",
    "            list: List of tuples containing matching (tif_path, zip_path) pairs\n",
    "        \"\"\"\n",
    "        concentrations = ['_0um', '_10um', '_25um']\n",
    "        matches = []\n",
    "        \n",
    "        tif_files = [f for f in os.listdir(self.base_dir) if f.endswith('.tif')]\n",
    "        zip_files = [f for f in os.listdir(self.base_dir) if f.endswith('.zip')]\n",
    "        \n",
    "        for tif_file in tif_files:\n",
    "            tif_path = os.path.join(self.base_dir, tif_file)\n",
    "            # Find concentration pattern in tif file\n",
    "            conc_pattern = next((c for c in concentrations if c in tif_file), None)\n",
    "            if conc_pattern:\n",
    "                # Look for matching zip file with same concentration\n",
    "                matching_zip = next((f for f in zip_files if conc_pattern in f), None)\n",
    "                if matching_zip:\n",
    "                    zip_path = os.path.join(self.base_dir, matching_zip)\n",
    "                    matches.append((tif_path, zip_path))\n",
    "        \n",
    "        return matches\n",
    "\n",
    "    def process_folder(self):\n",
    "        \"\"\"Process all matching .tif and .zip file pairs in the base directory.\"\"\"\n",
    "        matching_pairs = self.find_matching_files()\n",
    "        total_start = time.time()\n",
    "        \n",
    "        for tif_path, roi_path in matching_pairs:\n",
    "            pair_start = time.time()\n",
    "            logger.info(f\"\\nStarting processing of pair at {datetime.now()}:\")\n",
    "            logger.info(f\"TIF: {os.path.basename(tif_path)}\")\n",
    "            logger.info(f\"ROI: {os.path.basename(roi_path)}\")\n",
    "            \n",
    "            try:\n",
    "                # Reset timing dictionary for new pair\n",
    "                self.processing_times = {}\n",
    "                \n",
    "                # Process each stage with timing\n",
    "                stage_start = time.time()\n",
    "                memmap_path = self.exponential_correct_tif(tif_path)\n",
    "                self.log_time(\"Bleach Correction\", stage_start)\n",
    "                \n",
    "                stage_start = time.time()\n",
    "                masks_dir = self.convert_rois_to_masks(roi_path)\n",
    "                self.log_time(\"ROI Conversion\", stage_start)\n",
    "                \n",
    "                stage_start = time.time()\n",
    "                results = self.analyze_fluorescence(masks_dir)\n",
    "                self.log_time(\"Fluorescence Analysis\", stage_start)\n",
    "                \n",
    "                # Log total time for this pair\n",
    "                pair_time = self.log_time(f\"Total time for {os.path.basename(tif_path)}\", pair_start)\n",
    "                logger.info(f\"Successfully processed pair in {pair_time:.2f} seconds\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {os.path.basename(tif_path)}: {str(e)}\")\n",
    "        \n",
    "        # Log total processing time\n",
    "        total_time = time.time() - total_start\n",
    "        logger.info(f\"\\nTotal processing time for all pairs: {total_time:.2f} seconds\")\n",
    "\n",
    "    \n",
    "    def get_output_paths(self, input_tif: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Generate standardized output paths based on input .tif filename.\n",
    "        \n",
    "        Args:\n",
    "            input_tif (str): Path to input .tif file\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, str]: Dictionary containing all output paths\n",
    "        \"\"\"\n",
    "        # Extract the base name without extension\n",
    "        self.current_base_name = os.path.splitext(os.path.basename(input_tif))[0]\n",
    "        output_dir = os.path.dirname(input_tif)\n",
    "        \n",
    "        return {\n",
    "            'memmap': os.path.join(output_dir, f\"{self.current_base_name}_corrected.dat\"),\n",
    "            'masks_dir': os.path.join(output_dir, f\"{self.current_base_name}_masks\"),\n",
    "            'dff_traces': os.path.join(output_dir, f\"{self.current_base_name}_dff_traces.pkl\"),\n",
    "            'metrics': os.path.join(output_dir, f\"{self.current_base_name}_fluorescence_metrics.xlsx\")\n",
    "        }\n",
    "\n",
    "        \n",
    "    def exp(self, x: np.ndarray, a: float, b: float) -> np.ndarray:\n",
    "        return a * np.exp(-b * x)\n",
    "\n",
    "    def bi_exp(self, x: np.ndarray, a: float, b: float, c: float, d: float) -> np.ndarray:\n",
    "        return (a * np.exp(-b * x)) + (c * np.exp(-d * x))\n",
    "        \n",
    "    def find_background(self, images: np.ndarray, roi_shape: Tuple[int, int]) -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "        \"\"\"Modified to return both background values and ROI center\"\"\"\n",
    "        t, y, x = images.shape[0], images.shape[1], images.shape[2]\n",
    "        first_frame = images[0, :, :]\n",
    "        min_avg_fluorescence = np.inf\n",
    "        min_roi_center = None\n",
    "        \n",
    "        for i in range(0, y - roi_shape[0], roi_shape[0]):\n",
    "            for j in range(0, x - roi_shape[1], roi_shape[1]):\n",
    "                roi = first_frame[i:i + roi_shape[0], j:j + roi_shape[1]]\n",
    "                avg_fluorescence = np.mean(roi)\n",
    "                \n",
    "                if avg_fluorescence < min_avg_fluorescence:\n",
    "                    min_avg_fluorescence = avg_fluorescence\n",
    "                    min_roi_center = (i + roi_shape[0] // 2, j + roi_shape[1] // 2)\n",
    "\n",
    "        background = np.mean(images[:, \n",
    "                           min_roi_center[0] - roi_shape[0] // 2: min_roi_center[0] + roi_shape[0] // 2,\n",
    "                           min_roi_center[1] - roi_shape[1] // 2: min_roi_center[1] + roi_shape[1] // 2],\n",
    "                           axis=(1, 2))\n",
    "        \n",
    "        return background, min_roi_center\n",
    "\n",
    "    def exponential_correct_tif(self,\n",
    "            input_tif: str,\n",
    "            method: str = \"bi\",\n",
    "            contrast_limits: Tuple[int, int] = (0, 65535),\n",
    "            roi_shape: Tuple[int, int] = (10, 10)) -> str:\n",
    "        \"\"\"\n",
    "        Performs bleach correction on a .tif file.\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to the created memmap file\n",
    "        \"\"\"\n",
    "        paths = self.get_output_paths(input_tif)\n",
    "        self.memmap_path = paths['memmap']\n",
    "        \n",
    "        with tiff.TiffFile(input_tif) as tif:\n",
    "            images = tif.asarray()\n",
    "\n",
    "        dtype = np.uint16\n",
    "        shape = images.shape\n",
    "\n",
    "        assert 3 <= len(shape) <= 4, f\"Expected 3D or 4D stack, got {len(shape)}D\"\n",
    "\n",
    "        func = self.exp if method == \"mono\" else self.bi_exp\n",
    "        axes = tuple(range(1, len(shape)))\n",
    "        I_mean = np.mean(images, axis=axes)\n",
    "\n",
    "        x_data = np.arange(shape[0])\n",
    "        try:\n",
    "            popt, _ = curve_fit(func, x_data, I_mean)\n",
    "            f_ = func(x_data, *popt)\n",
    "        except (ValueError, RuntimeError, Warning):\n",
    "            f_ = np.ones_like(I_mean)\n",
    "\n",
    "        f = f_ / np.max(f_)\n",
    "        f = f.reshape((-1,) + (1,) * (len(shape) - 1))\n",
    "\n",
    "        corrected_memmap = np.memmap(self.memmap_path, dtype=dtype, mode='w+', shape=shape)\n",
    "        corrected_memmap[:] = np.clip(images / f, 0, 65535)\n",
    "        corrected_memmap[:] = np.clip(corrected_memmap, contrast_limits[0], contrast_limits[1])\n",
    "\n",
    "        logger.info(f\"Corrected image saved as a memmap at {self.memmap_path}\")\n",
    "        return self.memmap_path\n",
    "\n",
    "    def convert_rois_to_masks(self, roi_zip_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Converts ROIs to binary masks.\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to the masks directory\n",
    "        \"\"\"\n",
    "        paths = self.get_output_paths(self.memmap_path)\n",
    "        output_dir = paths['masks_dir']\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        rois = roiread(roi_zip_path)\n",
    "        \n",
    "        for i, roi in enumerate(rois):\n",
    "            mask = np.zeros(self.video_dims, dtype=np.uint16)\n",
    "            coords = roi.coordinates()\n",
    "            rr, cc = polygon(coords[:, 1], coords[:, 0], self.video_dims)\n",
    "            mask[rr, cc] = 255\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{self.current_base_name}_mask_{i+1:03d}.png\")\n",
    "            Image.fromarray(mask).save(output_path)\n",
    "            logger.info(f\"Saved mask: {output_path}\")\n",
    "            \n",
    "        return output_dir\n",
    "\n",
    "    # Define function to save dF/F traces externally (using pickle)\n",
    "    def save_dff_traces(self, dff_traces: Dict[str, np.ndarray], file_path: str):\n",
    "        \"\"\"Save dF/F traces to a pickle file\"\"\"\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(dff_traces, f)\n",
    "        logger.info(f\"Saved dF/F traces to {file_path}\")\n",
    "\n",
    "    # Define function to load dF/F traces from a pickle file\n",
    "    def load_dff_traces(self, file_path: str) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Load dF/F traces from a pickle file\"\"\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            dff_traces = pickle.load(f)\n",
    "        logger.info(f\"Loaded dF/F traces from {file_path}\")\n",
    "        return dff_traces\n",
    "    \n",
    "    def analyze_fluorescence(self, \n",
    "            masks_dir: str,\n",
    "            baseline_range: Tuple[int, int] = (0, 200),\n",
    "            analysis_range: Tuple[int, int] = (233, 580),\n",
    "            roi_shape: Tuple[int, int] = (100, 100)) -> pd.DataFrame:\n",
    "        \n",
    "        paths = self.get_output_paths(self.memmap_path)\n",
    "        stage_start = time.time()\n",
    "        \n",
    "        # Calculate distances first\n",
    "        distances = self.compute_distances(masks_dir)\n",
    "        \n",
    "        T, Y, X = self.get_video_shape()\n",
    "        video = np.memmap(self.memmap_path, dtype=np.uint16, mode='r', shape=(T, Y, X))\n",
    "        self.log_time(\"Video Loading\", stage_start)\n",
    "        \n",
    "        # Extract fluorescence traces in parallel\n",
    "        stage_start = time.time()\n",
    "        fluorescence_traces = self.extract_fluorescence_traces_parallel(video, masks_dir, roi_shape)\n",
    "        self.log_time(\"Fluorescence Extraction\", stage_start)\n",
    "        \n",
    "        # Calculate dF/F\n",
    "        stage_start = time.time()\n",
    "        dff_traces = self.calculate_dff(fluorescence_traces)\n",
    "        self.log_time(\"dF/F Calculation\", stage_start)\n",
    "        \n",
    "        # Save dF/F traces externally\n",
    "        self.save_dff_traces(dff_traces, paths['dff_traces'])\n",
    "        \n",
    "        # Compute metrics\n",
    "        stage_start = time.time()\n",
    "        metrics = self.compute_fluorescence_metrics(dff_traces, *baseline_range, *analysis_range)\n",
    "        self.log_time(\"Metrics Computation\", stage_start)\n",
    "        \n",
    "        # Create DataFrame with metrics\n",
    "        columns = [\"Peak Amplitude\", \"Time of Peak\", \"Std Dev\", \"AUC\", \"Max Rise Slope\",\n",
    "                  \"Time of Max Rise Slope\", \"Slope\", \"Rise Time\", \"Rise Slope\"]\n",
    "        df_metrics = pd.DataFrame.from_dict(metrics, orient='index', columns=columns)\n",
    "        \n",
    "        # Add background information to metrics\n",
    "        background_df = pd.DataFrame.from_dict(\n",
    "            {roi: {\n",
    "                'Background Mean': info['background_mean'],\n",
    "                'Background Std': info['background_std'],\n",
    "                'Background ROI Center X': info['background_roi_center'][1],\n",
    "                'Background ROI Center Y': info['background_roi_center'][0]\n",
    "            } for roi, info in self.background_values.items()},\n",
    "            orient='index'\n",
    "        )\n",
    "        \n",
    "        # Create distances DataFrame\n",
    "        df_distances = pd.DataFrame.from_dict(distances, orient='index', columns=['Distance to Lamina'])\n",
    "        \n",
    "        # Merge all the DataFrames\n",
    "        df_final = pd.concat([df_metrics, background_df, df_distances], axis=1)\n",
    "        \n",
    "        # Add processing times\n",
    "        df_final.attrs['processing_times'] = self.processing_times\n",
    "        \n",
    "        # Save results\n",
    "        df_final.to_excel(paths['metrics'])\n",
    "        logger.info(f\"Saved fluorescence metrics, background info, and distances to {paths['metrics']}\")\n",
    "        \n",
    "        # Save background traces separately\n",
    "        background_traces_path = os.path.join(os.path.dirname(paths['metrics']), \n",
    "                                            f\"{self.current_base_name}_background_traces.pkl\")\n",
    "        with open(background_traces_path, 'wb') as f:\n",
    "            pickle.dump(self.background_values, f)\n",
    "        logger.info(f\"Saved background traces to {background_traces_path}\")\n",
    "        \n",
    "        return df_final\n",
    "\n",
    "    def get_video_shape(self) -> Tuple[int, int, int]:\n",
    "        \"\"\"Gets the shape of the memory-mapped video.\"\"\"\n",
    "        file_size = os.path.getsize(self.memmap_path)\n",
    "        bytes_per_pixel = np.dtype(np.uint16).itemsize\n",
    "        t = file_size // (self.video_dims[0] * self.video_dims[1] * bytes_per_pixel)\n",
    "        \n",
    "        if file_size % (self.video_dims[0] * self.video_dims[1] * bytes_per_pixel) != 0:\n",
    "            raise ValueError(\"File size is not evenly divisible by expected frame size.\")\n",
    "            \n",
    "        return (t, *self.video_dims)\n",
    "\n",
    "    def extract_fluorescence_traces_parallel(self, video: np.ndarray, masks_dir: str, roi_shape: Tuple[int, int]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Extracts fluorescence traces in parallel.\"\"\"\n",
    "        fluorescence_traces = {}\n",
    "\n",
    "        # Using ThreadPoolExecutor for parallel processing of masks\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            # Create a list of future tasks for each ROI\n",
    "            future_to_roi = {\n",
    "                executor.submit(self.process_roi_trace, roi_filename, video, masks_dir, roi_shape): roi_filename\n",
    "                for roi_filename in sorted(os.listdir(masks_dir)) if roi_filename.endswith(\".png\")\n",
    "            }\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_roi):\n",
    "                roi_filename = future_to_roi[future]\n",
    "                try:\n",
    "                    # Retrieve the result for each completed task\n",
    "                    corrected_trace = future.result()\n",
    "                    fluorescence_traces[roi_filename] = corrected_trace\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing ROI {roi_filename}: {e}\")\n",
    "        \n",
    "        return fluorescence_traces\n",
    "\n",
    "    def process_roi_trace(self, roi_filename: str, video: np.ndarray, masks_dir: str, roi_shape: Tuple[int, int]) -> np.ndarray:\n",
    "        roi_path = os.path.join(masks_dir, roi_filename)\n",
    "        roi_mask = cv2.imread(roi_path, cv2.IMREAD_UNCHANGED) > 0\n",
    "        \n",
    "        # Vectorized computation\n",
    "        fluorescence_trace = np.mean(video[:, roi_mask], axis=1)\n",
    "        background, roi_center = self.find_background(video, roi_shape)\n",
    "        \n",
    "        # Store background information\n",
    "        self.background_values[roi_filename] = {\n",
    "            'background_trace': background,\n",
    "            'background_roi_center': roi_center,\n",
    "            'background_mean': np.mean(background),\n",
    "            'background_std': np.std(background)\n",
    "        }\n",
    "        \n",
    "        return np.clip(fluorescence_trace - background, 0, None)\n",
    "\n",
    "    # Define function to calculate dF/F\n",
    "    def calculate_dff(self, fluorescence_traces):\n",
    "        dff_traces = {} \n",
    "        for roi, trace in fluorescence_traces.items():\n",
    "            F0 = np.percentile(trace, 8)  # Baseline as 8th percentile\n",
    "            dff_traces[roi] = (trace - F0) / F0\n",
    "        return dff_traces\n",
    "\n",
    "    # Define function to compute fluorescence metrics\n",
    "    def compute_fluorescence_metrics(self, dff_traces, baseline_start=0, baseline_end=200, start=233, end=580):\n",
    "        \"\"\"Compute fluorescence metrics in parallel.\"\"\"\n",
    "        def compute_single_metric(roi_trace):\n",
    "            # Extract baseline and compute F0\n",
    "            baseline_segment = roi_trace[baseline_start:baseline_end]\n",
    "            F0 = np.mean(baseline_segment)\n",
    "            \n",
    "            # Get trace segment for analysis\n",
    "            trace_segment = roi_trace[start:end]\n",
    "            time_range = np.arange(start, end)\n",
    "            \n",
    "            # Peak metrics\n",
    "            peak_idx = np.argmax(trace_segment)\n",
    "            peak_amplitude = trace_segment[peak_idx] - F0\n",
    "            time_of_peak = time_range[peak_idx]\n",
    "            \n",
    "            # Other metrics\n",
    "            std_dev = np.std(trace_segment)\n",
    "            auc = np.trapz(trace_segment, dx=1)\n",
    "            \n",
    "            # Slope calculations\n",
    "            diff_trace = np.diff(trace_segment)\n",
    "            max_rise_idx = np.argmax(diff_trace)\n",
    "            max_rise_slope = diff_trace[max_rise_idx]\n",
    "            time_of_max_rise_slope = time_range[max_rise_idx]\n",
    "            slope, _, _, _, _ = linregress(time_range, trace_segment)\n",
    "            \n",
    "            # Rise time calculations\n",
    "            ten_percent = 0.1 * peak_amplitude\n",
    "            ninety_percent = 0.9 * peak_amplitude\n",
    "            try:\n",
    "                rise_start = np.where(trace_segment >= ten_percent)[0][0] + start\n",
    "                rise_end = np.where(trace_segment >= ninety_percent)[0][0] + start\n",
    "                rise_time = rise_end - rise_start\n",
    "                rise_slope = (ninety_percent - ten_percent) / rise_time\n",
    "            except IndexError:\n",
    "                rise_time = np.nan\n",
    "                rise_slope = np.nan\n",
    "                \n",
    "            return [peak_amplitude, time_of_peak, std_dev, auc,\n",
    "                   max_rise_slope, time_of_max_rise_slope, slope, rise_time, rise_slope]\n",
    "        \n",
    "        metrics = {}\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future_to_roi = {executor.submit(compute_single_metric, trace): roi \n",
    "                           for roi, trace in dff_traces.items()}\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_roi):\n",
    "                roi = future_to_roi[future]\n",
    "                try:\n",
    "                    metrics[roi] = future.result()\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing ROI {roi}: {e}\")\n",
    "                    metrics[roi] = [np.nan] * 9  # Fill with NaN if processing fails\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    # Define function to compute distance to laminar boundary\n",
    "    def compute_distances(self, roi_folder: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute distances from ROI centers to the laminar boundary (top of image).\n",
    "        \n",
    "        Args:\n",
    "            roi_folder (str): Path to folder containing ROI mask files\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, float]: Dictionary mapping ROI filenames to their distances from lamina\n",
    "        \"\"\"\n",
    "        distances = {}\n",
    "        for roi_filename in sorted(os.listdir(roi_folder)):\n",
    "            if roi_filename.endswith(\".png\"):\n",
    "                roi_path = os.path.join(roi_folder, roi_filename)\n",
    "                roi_mask = cv2.imread(roi_path, cv2.IMREAD_UNCHANGED) > 0\n",
    "                \n",
    "                # Find all non-zero points in the mask\n",
    "                y_indices, _ = np.where(roi_mask)\n",
    "                if len(y_indices) > 0:\n",
    "                    # Calculate center of ROI\n",
    "                    center_y = np.mean(y_indices)\n",
    "                    # Distance to lamina (top border, y=0)\n",
    "                    distance_to_lamina = center_y  \n",
    "                else:\n",
    "                    distance_to_lamina = np.nan\n",
    "                \n",
    "                distances[roi_filename] = distance_to_lamina\n",
    "                logger.debug(f\"ROI {roi_filename}: Distance to lamina = {distance_to_lamina:.2f} pixels\")\n",
    "        \n",
    "        return distances\n",
    "\n",
    "\n",
    "\n",
    "# Example usage to load dF/F traces externally\n",
    "def main():\n",
    "    base_dir = \"F:/Recovered/Research/BoninLab/PainModelingProject/calcium_imaging_data/@Disinhibition/Disinhib_m1_7.23.20/Disinhib_m1_s2\"\n",
    "    \n",
    "    # Initialize analysis pipeline\n",
    "    analysis = CalciumImagingAnalysis(base_dir)\n",
    "    \n",
    "    # Process all matching pairs in the folder\n",
    "    analysis.process_folder()\n",
    "    \n",
    "    # After processing, you can load specific dF/F traces if needed\n",
    "    traces_path = os.path.join(base_dir, \"dff_traces.pkl\")\n",
    "    if os.path.exists(traces_path):\n",
    "        dff_traces = analysis.load_dff_traces(traces_path)\n",
    "        return dff_traces\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    base_dir = \"path/to/your/data/folder\"\n",
    "#    analysis = CalciumImagingAnalysis(base_dir)\n",
    "#    analysis.process_folder()\n",
    "\n",
    "    # Example usage for processing a single file:\n",
    "   # analysis = CalciumImagingAnalysis(base_dir)\n",
    "   # memmap_path = analysis.exponential_correct_tif(\"your_file.tif\")\n",
    "    #masks_dir = analysis.convert_rois_to_masks(\"your_rois.zip\")\n",
    "   # results = analysis.analyze_fluorescence(masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978719c-1a2c-4b2a-a77e-ee04e1a64012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
